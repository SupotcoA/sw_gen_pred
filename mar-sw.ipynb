{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee3a6400",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:09:50.704436Z",
     "iopub.status.busy": "2025-10-27T15:09:50.704150Z",
     "iopub.status.idle": "2025-10-27T15:09:51.437386Z",
     "shell.execute_reply": "2025-10-27T15:09:51.436279Z"
    },
    "papermill": {
     "duration": 0.738193,
     "end_time": "2025-10-27T15:09:51.438963",
     "exception": false,
     "start_time": "2025-10-27T15:09:50.700770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'sw_gen_pred'...\r\n",
      "remote: Enumerating objects: 30, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\r\n",
      "remote: Total 30 (delta 10), reused 25 (delta 5), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (30/30), 520.32 KiB | 10.41 MiB/s, done.\r\n",
      "Resolving deltas: 100% (10/10), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SupotcoA/sw_gen_pred.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ce31ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:09:51.444768Z",
     "iopub.status.busy": "2025-10-27T15:09:51.444508Z",
     "iopub.status.idle": "2025-10-27T15:09:51.448222Z",
     "shell.execute_reply": "2025-10-27T15:09:51.447649Z"
    },
    "papermill": {
     "duration": 0.007885,
     "end_time": "2025-10-27T15:09:51.449364",
     "exception": false,
     "start_time": "2025-10-27T15:09:51.441479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/working/sw_gen_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711ac5fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:09:51.454143Z",
     "iopub.status.busy": "2025-10-27T15:09:51.453908Z",
     "iopub.status.idle": "2025-10-27T15:09:55.331405Z",
     "shell.execute_reply": "2025-10-27T15:09:55.330551Z"
    },
    "papermill": {
     "duration": 3.8815,
     "end_time": "2025-10-27T15:09:55.332917",
     "exception": false,
     "start_time": "2025-10-27T15:09:51.451417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49a2028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:09:55.338941Z",
     "iopub.status.busy": "2025-10-27T15:09:55.338091Z",
     "iopub.status.idle": "2025-10-27T15:10:00.841177Z",
     "shell.execute_reply": "2025-10-27T15:10:00.840555Z"
    },
    "papermill": {
     "duration": 5.50753,
     "end_time": "2025-10-27T15:10:00.842800",
     "exception": false,
     "start_time": "2025-10-27T15:09:55.335270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from train import train\n",
    "from build_model import build_model\n",
    "from data import build_dataset\n",
    "from utils import Logger\n",
    "\n",
    "import traceback\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b09050e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:10:00.848462Z",
     "iopub.status.busy": "2025-10-27T15:10:00.847729Z",
     "iopub.status.idle": "2025-10-27T15:10:00.855727Z",
     "shell.execute_reply": "2025-10-27T15:10:00.854948Z"
    },
    "papermill": {
     "duration": 0.011805,
     "end_time": "2025-10-27T15:10:00.856889",
     "exception": false,
     "start_time": "2025-10-27T15:10:00.845084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_config = dict(\n",
    "    ver=\"gen_pred_test3\",\n",
    "    description=\"scale up\",\n",
    "    outcome_root=\"/kaggle/working\",\n",
    ")\n",
    "global_config[\"outcome_dir_root\"] = os.path.join(global_config[\"outcome_root\"],\n",
    "                                                 global_config[\"ver\"])\n",
    "seg_size=4\n",
    "n_features=9\n",
    "transformer_config=dict(\n",
    "    inp_dim = n_features*seg_size*2,\n",
    "    dim = 128,\n",
    "    out_dim = 128,\n",
    "    num_layers = 8,\n",
    "    num_heads = 8,\n",
    "    ff_hidden_dim = 320,\n",
    "    max_seq_len = 64,\n",
    "    dropout = 0.0\n",
    ")\n",
    "\n",
    "\n",
    "mlp_config=dict(\n",
    "    in_channels=n_features*seg_size,\n",
    "    model_channels=128,\n",
    "    out_channels=n_features*seg_size,\n",
    "    z_channels=transformer_config['out_dim'],\n",
    "    num_res_blocks=4,\n",
    "    grad_checkpointing=False\n",
    ")\n",
    "\n",
    "\n",
    "diffusion_config=dict(\n",
    "    num_steps = 64\n",
    ")\n",
    "\n",
    "train_config=dict(\n",
    "    seg_size=seg_size,\n",
    "    num_fm_per_gd=8,\n",
    "    max_seq_len=transformer_config['max_seq_len'],\n",
    "    train_steps=40000,\n",
    "    log_every_n_steps=4000,\n",
    "    eval_every_n_steps=8000,\n",
    "    pretrained=None,\n",
    "    batch_size=256,\n",
    "    base_learning_rate=3.0e-4,\n",
    "    min_learning_rate=1.0e-4,\n",
    "    use_lr_scheduler=True,\n",
    "    warmup_steps=500,\n",
    "    betas=[0.98, 0.999],\n",
    "    need_check=False,\n",
    "    use_ema=False,\n",
    "    ema_decay=0.9999,\n",
    "    ema_steps=20000\n",
    ")\n",
    "train_config['save']=train_config['train_steps']>0\n",
    "\n",
    "img_dataset_paths={'afhq':'/kaggle/input/afhq-512',\n",
    "               'ffhq':'/kaggle/input/flickrfaceshq-dataset-nvidia-resized-256px',\n",
    "               'celebahq':'/kaggle/input/celebahq256-images-only',\n",
    "               'fa':'/kaggle/input/face-attributes-grouped',\n",
    "               'animestyle':'/kaggle/input/gananime-lite',\n",
    "               'animefaces':'/kaggle/input/another-anime-face-dataset',\n",
    "              }\n",
    "\n",
    "data_config = dict(\n",
    "    shape=(train_config['batch_size'],\n",
    "           train_config['max_seq_len']*seg_size,\n",
    "           n_features),\n",
    "    image_size=256,\n",
    "    batch_size=train_config['batch_size'],\n",
    "    ae_batch_size=48,\n",
    "    split=[0.8,0.1,0.1],\n",
    "    space_weather_data_root=\"/kaggle/input/sw-2012-v0\",\n",
    "    data_paths=img_dataset_paths,\n",
    "    enc_path=os.path.join(global_config[\"outcome_dir_root\"], \"enc\"),\n",
    "    enc_inp_path='/kaggle/input/sd-vae-ft-ema-f8-256-faces6-enc',\n",
    "    dataset_names=['afhq', 'ffhq', 'celebahq', 'fa', 'animestyle', 'animefaces'],\n",
    "    ignored_dataset=['fa'],\n",
    "    ignored_dataset_ft=['ffhq', 'celebahq', 'animestyle', 'animefaces'],\n",
    "    valid_dataset_idx=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6523b8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:10:00.861576Z",
     "iopub.status.busy": "2025-10-27T15:10:00.861358Z",
     "iopub.status.idle": "2025-10-27T15:10:00.866268Z",
     "shell.execute_reply": "2025-10-27T15:10:00.865743Z"
    },
    "papermill": {
     "duration": 0.00848,
     "end_time": "2025-10-27T15:10:00.867374",
     "exception": false,
     "start_time": "2025-10-27T15:10:00.858894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = Logger(log_every_n_steps=train_config['log_every_n_steps'],\n",
    "                log_root=global_config[\"outcome_dir_root\"],\n",
    "                model_name=global_config['ver']\n",
    "               )\n",
    "\n",
    "logger.log_text(str(global_config), \"config\")\n",
    "logger.log_text(str(mlp_config), \"config\", newline=True)\n",
    "logger.log_text(str(transformer_config), \"config\", newline=True)\n",
    "logger.log_text(str(diffusion_config), \"config\", newline=True)\n",
    "logger.log_text(str(train_config), \"config\", newline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f438d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:10:00.872693Z",
     "iopub.status.busy": "2025-10-27T15:10:00.872243Z",
     "iopub.status.idle": "2025-10-27T15:10:01.366677Z",
     "shell.execute_reply": "2025-10-27T15:10:01.365719Z"
    },
    "papermill": {
     "duration": 0.498081,
     "end_time": "2025-10-27T15:10:01.367770",
     "exception": false,
     "start_time": "2025-10-27T15:10:00.869689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data: ACE_Bz_2012 ACE_Psw_2012 ACE_Vsw_2012 OMNI_AE_2012 OMNI_ASYMH_2012 OMNI_PC_2012 OMNI_SYMH_2012\n",
      "All data cat shape: torch.Size([527040, 8])\n",
      "train data len 421632\n",
      "val data len 52704\n",
      "test data len 52704\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42+hash(global_config['ver'])%10000)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = build_dataset(data_config)\n",
    "\n",
    "logger.log_text(str(data_config), \"config\", newline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2c8951",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:10:01.373219Z",
     "iopub.status.busy": "2025-10-27T15:10:01.372649Z",
     "iopub.status.idle": "2025-10-27T15:10:01.589819Z",
     "shell.execute_reply": "2025-10-27T15:10:01.589051Z"
    },
    "papermill": {
     "duration": 0.221013,
     "end_time": "2025-10-27T15:10:01.591038",
     "exception": false,
     "start_time": "2025-10-27T15:10:01.370025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T params: 1,528,064, MLP params: 432,392, TTrainable: 1,528,064\n",
      "running on cuda\n"
     ]
    }
   ],
   "source": [
    "model, optim, lr_scheduler = build_model(logger,\n",
    "                                         transformer_config,\n",
    "                                         mlp_config,\n",
    "                                         diffusion_config,\n",
    "                                         train_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289adacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-27T15:10:01.596574Z",
     "iopub.status.busy": "2025-10-27T15:10:01.596339Z",
     "iopub.status.idle": "2025-10-27T17:34:36.965675Z",
     "shell.execute_reply": "2025-10-27T17:34:36.964773Z"
    },
    "papermill": {
     "duration": 8675.373842,
     "end_time": "2025-10-27T17:34:36.967254",
     "exception": false,
     "start_time": "2025-10-27T15:10:01.593412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 4000\n",
      "loss: 0.1561\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Train step 8000\n",
      "loss: 0.0619\n",
      "time per kstep: 215\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Eval\n",
      "loss:0.0513+-0.0195\n",
      "\n",
      "Train step 12000\n",
      "loss: 0.0589\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Train step 16000\n",
      "loss: 0.0574\n",
      "time per kstep: 215\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Eval\n",
      "loss:0.0506+-0.0202\n",
      "\n",
      "Train step 20000\n",
      "loss: 0.0553\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Train step 24000\n",
      "loss: 0.0524\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Eval\n",
      "loss:0.0582+-0.0248\n",
      "\n",
      "Train step 28000\n",
      "loss: 0.0487\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Train step 32000\n",
      "loss: 0.0448\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Eval\n",
      "loss:0.0710+-0.0332\n",
      "\n",
      "Train step 36000\n",
      "loss: 0.0412\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Train step 40000\n",
      "loss: 0.0384\n",
      "time per kstep: 216\n",
      "peak GPU mem: 5.3 GB\n",
      "\n",
      "Eval\n",
      "loss:0.0869+-0.0452\n",
      "\n",
      "generating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/sw_gen_pred/utils.py:121: UserWarning: Attempt to set non-positive ylim on a log-scaled axis will be ignored.\n",
      "  plt.ylim([0,0.08])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "loss:0.0744+-0.0192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train(model, optim, lr_scheduler, train_config,\n",
    "          train_dataset, val_dataset, test_dataset, logger)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    info = traceback.format_exc()\n",
    "    info = f\"Exception: {str(info)} \\n\"+\\\n",
    "            f\"Step: {logger.step}\"\n",
    "    print(info)\n",
    "    logger.log_text(info, \"error\")\n",
    "finally:\n",
    "    if not any([fn.endswith('.pth') for fn in os.listdir(logger.log_root)]):\n",
    "        if train_config['save']:\n",
    "            logger.log_net(model.cpu(),f\"mar_{logger.step}\")\n",
    "    shutil.make_archive(global_config[\"outcome_dir_root\"],\n",
    "                        'zip',\n",
    "                        global_config[\"outcome_dir_root\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628ae36",
   "metadata": {
    "papermill": {
     "duration": 0.002705,
     "end_time": "2025-10-27T17:34:36.973095",
     "exception": false,
     "start_time": "2025-10-27T17:34:36.970390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8583697,
     "sourceId": 13518968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8691.851323,
   "end_time": "2025-10-27T17:34:38.797831",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-27T15:09:46.946508",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
